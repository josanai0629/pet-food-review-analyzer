{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ãƒšãƒƒãƒˆãƒ•ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†é¡å™¨ - ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•ã‚’å­¦ã³ã¾ã™ã€‚\n",
    "\n",
    "## ğŸ¯ ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§å­¦ã¶ã“ã¨\n",
    "\n",
    "1. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†\n",
    "2. æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æï¼ˆEDAï¼‰\n",
    "3. BERTãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’\n",
    "4. ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã¨äºˆæ¸¬\n",
    "\n",
    "## ğŸ“‹ å‰ææ¡ä»¶\n",
    "\n",
    "- `ãƒ©ãƒ™ãƒ«ä»˜ã‘å‚è€ƒç”¨.xlsx` ãƒ•ã‚¡ã‚¤ãƒ«ãŒæº–å‚™ã•ã‚Œã¦ã„ã‚‹ã“ã¨\n",
    "- å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ (`pip install -r requirements.txt`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒè¨­å®šã¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ \n",
    "current_dir = os.getcwd()\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "\n",
    "# å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "from data_preprocessing import DataPreprocessor\n",
    "from eda import EDAAnalyzer\n",
    "from bert_classifier import BERTClassifier\n",
    "from config import MODEL_CONFIG, DATA_CONFIG\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {torch.__version__}\")\n",
    "print(f\"CUDAåˆ©ç”¨å¯èƒ½: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "\n",
    "print(\"\\nâœ… ç’°å¢ƒè¨­å®šå®Œäº†ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è¨­å®š\n",
    "excel_file = \"../ãƒ©ãƒ™ãƒ«ä»˜ã‘å‚è€ƒç”¨.xlsx\"  # ãƒ‘ã‚¹ã‚’é©åˆ‡ã«èª¿æ•´ã—ã¦ãã ã•ã„\n",
    "\n",
    "# ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª\n",
    "if os.path.exists(excel_file):\n",
    "    print(f\"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {excel_file}\")\n",
    "    \n",
    "    # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’è¡¨ç¤º\n",
    "    file_size = os.path.getsize(excel_file) / 1024 / 1024  # MB\n",
    "    print(f\"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:.2f} MB\")\n",
    "else:\n",
    "    print(f\"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {excel_file}\")\n",
    "    print(\"   ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„\")\n",
    "    excel_file = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if excel_file and os.path.exists(excel_file):\n",
    "    print(\"ğŸ“Š ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚’é–‹å§‹...\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†å™¨ã®åˆæœŸåŒ–\n",
    "    preprocessor = DataPreprocessor()\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†\n",
    "    processed_data = preprocessor.process_data(excel_file)\n",
    "    \n",
    "    # çµæœã®è¡¨ç¤º\n",
    "    print(f\"\\nğŸ“ˆ å‰å‡¦ç†çµæœ:\")\n",
    "    print(f\"   ç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(processed_data['texts'])}\")\n",
    "    print(f\"   ãƒ©ãƒ™ãƒ«æ•°: {len(processed_data['label_encoder'].classes_)}\")\n",
    "    print(f\"   å¹³å‡æ–‡å­—æ•°: {np.mean([len(text) for text in processed_data['texts']]):.1f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ·ï¸ ãƒ©ãƒ™ãƒ«ä¸€è¦§:\")\n",
    "    for i, label in enumerate(processed_data['label_encoder'].classes_):\n",
    "        count = list(processed_data['original_labels']).count(label)\n",
    "        percentage = count / len(processed_data['original_labels']) * 100\n",
    "        print(f\"   {i+1}. {label}: {count}ä»¶ ({percentage:.1f}%)\")\n",
    "        \n",
    "    print(\"\\nâœ… ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†å®Œäº†ï¼\")\n",
    "else:\n",
    "    print(\"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æï¼ˆEDAï¼‰\n",
    "\n",
    "ãƒ‡ãƒ¼ã‚¿ã®åˆ†å¸ƒã‚„ç‰¹å¾´ã‚’è¦–è¦šçš„ã«ç¢ºèªã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'processed_data' in locals():\n",
    "    print(\"ğŸ“Š EDAåˆ†æã‚’é–‹å§‹...\")\n",
    "    \n",
    "    # EDAåˆ†æå™¨ã®åˆæœŸåŒ–\n",
    "    eda_analyzer = EDAAnalyzer()\n",
    "    \n",
    "    # DataFrameã‚’å–å¾—\n",
    "    df = processed_data['dataframe']\n",
    "    \n",
    "    # åŸºæœ¬çµ±è¨ˆæƒ…å ±\n",
    "    basic_stats = eda_analyzer.analyze_basic_statistics(df)\n",
    "    \n",
    "    print(\"\\nâœ… åŸºæœ¬çµ±è¨ˆæƒ…å ±åˆ†æå®Œäº†ï¼\")\n",
    "else:\n",
    "    print(\"âŒ å‰å‡¦ç†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ©ãƒ™ãƒ«åˆ†å¸ƒã®å¯è¦–åŒ–\n",
    "if 'df' in locals():\n",
    "    eda_analyzer.plot_label_distribution(df)\n",
    "    print(\"ğŸ“Š ãƒ©ãƒ™ãƒ«åˆ†å¸ƒã‚’è¡¨ç¤ºä¸­...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ†ã‚­ã‚¹ãƒˆé•·ã®åˆ†æ\n",
    "if 'df' in locals():\n",
    "    eda_analyzer.plot_text_length_analysis(df)\n",
    "    print(\"ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆé•·åˆ†æã‚’è¡¨ç¤ºä¸­...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã®åˆ†æ\n",
    "if 'df' in locals():\n",
    "    imbalance_analysis = eda_analyzer.analyze_class_imbalance(df)\n",
    "    print(\"âš–ï¸ ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡åˆ†æå®Œäº†ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ç¢ºèª\n",
    "\n",
    "å„ãƒ©ãƒ™ãƒ«ã®å®Ÿéš›ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾‹ã‚’ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    eda_analyzer.show_sample_reviews(df, n_samples=3)\n",
    "    print(\"\\nğŸ‘€ ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºå®Œäº†ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. BERTåˆ†é¡å™¨ã®å­¦ç¿’\n",
    "\n",
    "ã„ã‚ˆã„ã‚ˆBERTãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¾ã™ã€‚GPUãŒã‚ã‚‹å ´åˆã¯è‡ªå‹•çš„ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚\n",
    "\n",
    "âš ï¸ **æ³¨æ„**: åˆå›å®Ÿè¡Œæ™‚ã¯BERTãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼ˆæ•°åˆ†ã€œ10åˆ†ç¨‹åº¦ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'processed_data' in locals():\n",
    "    print(\"ğŸ¤– BERTåˆ†é¡å™¨ã®å­¦ç¿’ã‚’é–‹å§‹...\")\n",
    "    print(\"   â° åˆå›å®Ÿè¡Œæ™‚ã¯ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™\")\n",
    "    \n",
    "    # BERTåˆ†é¡å™¨ã®åˆæœŸåŒ–\n",
    "    classifier = BERTClassifier()\n",
    "    \n",
    "    # å­¦ç¿’è¨­å®šã‚’è¡¨ç¤º\n",
    "    print(f\"\\nâš™ï¸ å­¦ç¿’è¨­å®š:\")\n",
    "    print(f\"   ãƒ¢ãƒ‡ãƒ«: {MODEL_CONFIG['bert_model_name']}\")\n",
    "    print(f\"   ã‚¨ãƒãƒƒã‚¯æ•°: {MODEL_CONFIG['num_epochs']}\")\n",
    "    print(f\"   ãƒãƒƒãƒã‚µã‚¤ã‚º: {MODEL_CONFIG['batch_size']}\")\n",
    "    print(f\"   å­¦ç¿’ç‡: {MODEL_CONFIG['learning_rate']}\")\n",
    "    print(f\"   ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "    \n",
    "    # å­¦ç¿’å®Ÿè¡Œï¼ˆã‚¨ãƒãƒƒã‚¯æ•°ã‚’å°‘ãªã‚ã«è¨­å®šï¼‰\n",
    "    training_results = classifier.train(\n",
    "        processed_data=processed_data,\n",
    "        epochs=3,  # ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆãªã®ã§3ã‚¨ãƒãƒƒã‚¯\n",
    "        use_class_weights=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nğŸ‰ å­¦ç¿’å®Œäº†ï¼\")\n",
    "    print(f\"   ãƒ†ã‚¹ãƒˆç²¾åº¦: {training_results['test_results']['eval_accuracy']:.4f}\")\n",
    "    print(f\"   ãƒ†ã‚¹ãƒˆF1: {training_results['test_results']['eval_f1']:.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ å‰å‡¦ç†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã¨äºˆæ¸¬\n",
    "\n",
    "å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã§å®Ÿéš›ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†é¡ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'classifier' in locals():\n",
    "    print(\"ğŸ§ª ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ...\")\n",
    "    \n",
    "    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹\n",
    "    test_cases = [\n",
    "        {\n",
    "            'text': 'ä»Šã¾ã§ãƒ‰ãƒ©ã‚¤ãƒ•ãƒ¼ãƒ‰ã‚’è‰²ã€…è©¦ã—ã¦ãã¾ã—ãŸãŒã€ã©ã‚Œã‚‚ã¡ã‚ƒã‚“ã¨é£Ÿã¹ãšã«æ®‹ã—ã¦ã¾ã—ãŸã€‚ã“ã¡ã‚‰ã¯åˆã‚ã¦ä¸ãˆãŸç¬é–“ã‹ã‚‰é£›ã³ä»˜ã„ã¦å–œã‚“ã§å®Œé£Ÿã—ã¦ãã‚Œã¾ã—ãŸã€‚',\n",
    "            'expected': 'é£Ÿã¹ã‚‹'\n",
    "        },\n",
    "        {\n",
    "            'text': 'ã†ã¡ã®çŒ«ã¯ã“ã‚Œã‚’é£Ÿã¹ã‚‹ã¨ã€ä¸‹ç—¢ã§ã—ãŸ',\n",
    "            'expected': 'åããƒ»ä¾¿ãŒæ‚ªããªã‚‹'\n",
    "        },\n",
    "        {\n",
    "            'text': 'é…é€ã®ç®±ãŒç ´ã‚Œã¦ã„ã¦ä¸­èº«ãŒã“ã¼ã‚Œã¦ã„ã¾ã—ãŸ',\n",
    "            'expected': 'é…é€ãƒ»æ¢±åŒ…'\n",
    "        },\n",
    "        {\n",
    "            'text': 'å€¤æ®µãŒé«˜ããªã£ã¦ãã¦å›°ã‚Šã¾ã™',\n",
    "            'expected': 'å€¤ä¸ŠãŒã‚Š/é«˜ã„'\n",
    "        },\n",
    "        {\n",
    "            'text': 'ã‚³ã‚¹ãƒ‘ãŒè‰¯ãã¦åŠ©ã‹ã‚Šã¾ã™',\n",
    "            'expected': 'å®‰ã„'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nğŸ“ ãƒ†ã‚¹ãƒˆçµæœ:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    correct_count = 0\n",
    "    \n",
    "    for i, test_case in enumerate(test_cases, 1):\n",
    "        # äºˆæ¸¬å®Ÿè¡Œ\n",
    "        prediction = classifier.predict(\n",
    "            test_case['text'], \n",
    "            return_probabilities=True\n",
    "        )\n",
    "        \n",
    "        # çµæœã®ç¢ºèª\n",
    "        is_correct = prediction['predicted_label'] == test_case['expected']\n",
    "        if is_correct:\n",
    "            correct_count += 1\n",
    "        \n",
    "        # çµæœè¡¨ç¤º\n",
    "        print(f\"\\nãƒ†ã‚¹ãƒˆ {i}:\")\n",
    "        print(f\"   ãƒ†ã‚­ã‚¹ãƒˆ: {test_case['text'][:50]}...\")\n",
    "        print(f\"   æœŸå¾…å€¤: {test_case['expected']}\")\n",
    "        print(f\"   äºˆæ¸¬: {prediction['predicted_label']} (ç¢ºä¿¡åº¦: {prediction['confidence']:.3f})\")\n",
    "        print(f\"   çµæœ: {'âœ… æ­£è§£' if is_correct else 'âŒ ä¸æ­£è§£'}\")\n",
    "    \n",
    "    # å…¨ä½“ã®æ­£è§£ç‡\n",
    "    accuracy = correct_count / len(test_cases)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"ğŸ¯ ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹æ­£è§£ç‡: {accuracy:.1%} ({correct_count}/{len(test_cases)})\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. è©³ç´°ãªäºˆæ¸¬çµæœã®ç¢ºèª\n",
    "\n",
    "ç‰¹å®šã®ãƒ†ã‚­ã‚¹ãƒˆã«ã¤ã„ã¦ã€å…¨ãƒ©ãƒ™ãƒ«ã®ç¢ºç‡ã‚’ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'classifier' in locals():\n",
    "    # è¤‡é›‘ãªã‚±ãƒ¼ã‚¹ã‚’ãƒ†ã‚¹ãƒˆ\n",
    "    complex_text = \"\"\"å‰ã¯ä»–ã®ãƒ•ãƒ¼ãƒ‰ã‚’é£Ÿã¹ã¦ã„ã¾ã—ãŸãŒæ®‹ã™ã“ã¨ãŒå¤šãã¦å›°ã£ã¦ã„ã¾ã—ãŸã€‚\n",
    "    ã§ã‚‚ã“ã¡ã‚‰ã«å¤‰ãˆã¦ã‹ã‚‰ã¯å®Œé£Ÿã—ã¦ãã‚Œã‚‹ã‚ˆã†ã«ãªã‚Šã€ã†ã‚“ã¡ã®èª¿å­ã‚‚è‰¯ããªã‚Šã¾ã—ãŸã€‚\n",
    "    ãŸã ã€ãŠå€¤æ®µãŒå°‘ã—é«˜ã„ã®ãŒæ°—ã«ãªã‚Šã¾ã™ã€‚\"\"\"\n",
    "    \n",
    "    print(\"ğŸ” è¤‡é›‘ãªãƒ†ã‚­ã‚¹ãƒˆã®è©³ç´°åˆ†æ:\")\n",
    "    print(f\"ãƒ†ã‚­ã‚¹ãƒˆ: {complex_text}\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    # äºˆæ¸¬å®Ÿè¡Œ\n",
    "    prediction = classifier.predict(complex_text, return_probabilities=True)\n",
    "    \n",
    "    # æœ€ã‚‚ç¢ºç‡ã®é«˜ã„ãƒ©ãƒ™ãƒ«\n",
    "    print(f\"\\nğŸ† æœ€çµ‚äºˆæ¸¬: {prediction['predicted_label']} (ç¢ºä¿¡åº¦: {prediction['confidence']:.3f})\")\n",
    "    \n",
    "    # å…¨ãƒ©ãƒ™ãƒ«ã®ç¢ºç‡ã‚’è¡¨ç¤º\n",
    "    print(f\"\\nğŸ“Š å…¨ãƒ©ãƒ™ãƒ«ã®ç¢ºç‡:\")\n",
    "    sorted_probs = sorted(\n",
    "        prediction['all_probabilities'].items(), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    for rank, (label, prob) in enumerate(sorted_probs, 1):\n",
    "        bar = \"â–ˆ\" * int(prob * 20)  # ç¢ºç‡ã‚’æ£’ã‚°ãƒ©ãƒ•ã§è¡¨ç¾\n",
    "        print(f\"   {rank:2d}. {label:20s} {prob:.3f} {bar}\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªäºˆæ¸¬\n",
    "\n",
    "è‡ªç”±ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦äºˆæ¸¬ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'classifier' in locals():\n",
    "    print(\"ğŸ® ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰\")\n",
    "    print(\"ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ã€è‡ªç”±ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼\")\n",
    "    print(\"ï¼ˆç©ºæ–‡å­—ã‚’å…¥åŠ›ã™ã‚‹ã¨çµ‚äº†ã—ã¾ã™ï¼‰\")\n",
    "    \n",
    "    def interactive_prediction():\n",
    "        while True:\n",
    "            user_text = input(\"\\näºˆæ¸¬ã—ãŸã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: \")\n",
    "            \n",
    "            if not user_text.strip():\n",
    "                print(\"äºˆæ¸¬ã‚’çµ‚äº†ã—ã¾ã™ã€‚\")\n",
    "                break\n",
    "            \n",
    "            try:\n",
    "                prediction = classifier.predict(user_text, return_probabilities=True)\n",
    "                \n",
    "                print(f\"\\nğŸ“ å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ: {user_text}\")\n",
    "                print(f\"ğŸ¯ äºˆæ¸¬ãƒ©ãƒ™ãƒ«: {prediction['predicted_label']}\")\n",
    "                print(f\"ğŸ“Š ç¢ºä¿¡åº¦: {prediction['confidence']:.3f}\")\n",
    "                \n",
    "                # ä¸Šä½3ã¤ã®å€™è£œã‚’è¡¨ç¤º\n",
    "                sorted_probs = sorted(\n",
    "                    prediction['all_probabilities'].items(), \n",
    "                    key=lambda x: x[1], \n",
    "                    reverse=True\n",
    "                )[:3]\n",
    "                \n",
    "                print(\"\\nğŸ† ä¸Šä½å€™è£œ:\")\n",
    "                for i, (label, prob) in enumerate(sorted_probs, 1):\n",
    "                    print(f\"   {i}. {label}: {prob:.3f}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
    "    \n",
    "    # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹\n",
    "    # æ³¨æ„: Jupyterç’°å¢ƒã§ã¯ä»¥ä¸‹ã®è¡Œã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦ãã ã•ã„\n",
    "    # interactive_prediction()\n",
    "    \n",
    "    print(\"\\nğŸ’¡ ãƒ’ãƒ³ãƒˆ: ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ†ã‚­ã‚¹ãƒˆã‚’è©¦ã—ã¦ã¿ã¦ãã ã•ã„:\")\n",
    "    print(\"   - 'ã‚ˆãé£Ÿã¹ã¦ãã‚Œã¾ã™'\")\n",
    "    print(\"   - 'å…¨ç„¶é£Ÿã¹ã¾ã›ã‚“'\")\n",
    "    print(\"   - 'å±Šã„ãŸç®±ãŒã¸ã“ã‚“ã§ã„ã¾ã—ãŸ'\")\n",
    "    print(\"   - 'ã‚‚ã†å°‘ã—å®‰ã„ã¨ã„ã„ã®ã§ã™ãŒ'\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ã¾ã¨ã‚ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "### ğŸ‰ å®Œäº†ã—ãŸã“ã¨\n",
    "\n",
    "1. âœ… ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†\n",
    "2. âœ… æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æï¼ˆEDAï¼‰\n",
    "3. âœ… BERTãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’\n",
    "4. âœ… ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã¨äºˆæ¸¬\n",
    "5. âœ… ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªäºˆæ¸¬ãƒ†ã‚¹ãƒˆ\n",
    "\n",
    "### ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã®ãŸã‚ã«\n",
    "\n",
    "- **ã‚ˆã‚Šå¤šãã®ã‚¨ãƒãƒƒã‚¯**: `epochs=5` ã‚„ `epochs=10` ã§å­¦ç¿’\n",
    "- **GPUä½¿ç”¨**: ã‚ˆã‚Šé«˜é€Ÿãªå­¦ç¿’\n",
    "- **ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´**: å­¦ç¿’ç‡ã‚„ãƒãƒƒãƒã‚µã‚¤ã‚ºã®æœ€é©åŒ–\n",
    "- **ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’**: è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®çµ„ã¿åˆã‚ã›\n",
    "\n",
    "### ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "1. **æœ¬æ ¼çš„ãªå­¦ç¿’**: `train.py`ã‚’ä½¿ç”¨ã—ãŸå®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³\n",
    "2. **ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨èª­ã¿è¾¼ã¿**: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®å†åˆ©ç”¨\n",
    "3. **APIåŒ–**: Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¸ã®çµ±åˆ\n",
    "4. **ç¶™ç¶šçš„æ”¹å–„**: æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§ã®å†å­¦ç¿’\n",
    "\n",
    "### ğŸ’¡ å‚è€ƒã‚³ãƒãƒ³ãƒ‰\n",
    "\n",
    "```bash\n",
    "# å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œ\n",
    "python train.py --excel_file \"../ãƒ©ãƒ™ãƒ«ä»˜ã‘å‚è€ƒç”¨.xlsx\" --epochs 10 --gpu\n",
    "\n",
    "# ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿\n",
    "classifier = BERTClassifier()\n",
    "classifier.load_saved_model(\"./models/\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸŠ ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼ãƒšãƒƒãƒˆãƒ•ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†é¡å™¨ã®åŸºæœ¬çš„ãªä½¿ã„æ–¹ã‚’ãƒã‚¹ã‚¿ãƒ¼ã—ã¾ã—ãŸï¼**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
